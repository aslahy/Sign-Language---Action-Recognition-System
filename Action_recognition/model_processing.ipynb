{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import mediapipe as mp\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mediapipe Setup\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_holistic = mp.solutions.holistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your subfolders and labels\n",
    "subfolders = ['hello', 'goodbye', 'please', 'thankyou', 'yes', 'no']  # Example subfolders named '1' to '5'\n",
    "DATA_PATH = \"./actions\"  # Path to the main folder containing subfolders\n",
    "sequence_length = 30  # Number of frames per sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Map: {'hello': 0, 'goodbye': 1, 'please': 2, 'thankyou': 3, 'yes': 4, 'no': 5}\n"
     ]
    }
   ],
   "source": [
    "# Create a label map for the subfolders\n",
    "label_map = {folder: num for num, folder in enumerate(subfolders)}\n",
    "print(\"Label Map:\", label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing folder hello:   0%|          | 0/80 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing folder hello: 100%|██████████| 80/80 [00:30<00:00,  2.63it/s]\n",
      "Processing folder goodbye: 100%|██████████| 80/80 [00:26<00:00,  3.00it/s]\n",
      "Processing folder please: 100%|██████████| 80/80 [00:23<00:00,  3.40it/s]\n",
      "Processing folder thankyou: 100%|██████████| 80/80 [00:25<00:00,  3.16it/s]\n",
      "Processing folder yes: 100%|██████████| 80/80 [00:25<00:00,  3.11it/s]\n",
      "Processing folder no: 100%|██████████| 80/80 [00:31<00:00,  2.56it/s]\n"
     ]
    }
   ],
   "source": [
    "# Initialize sequences and labels\n",
    "sequences, labels = [], []\n",
    "\n",
    "# Iterate through each subfolder and gather sequences with progress tracking\n",
    "for folder in subfolders:\n",
    "    folder_path = os.path.join(DATA_PATH, folder)\n",
    "    \n",
    "    # Process each video in the folder, ensuring only `.mp4` files are selected\n",
    "    for video_file in tqdm([f for f in os.listdir(folder_path) if f.endswith('.mp4')], desc=f\"Processing folder {folder}\"):\n",
    "        window = []\n",
    "        missing_frames = False\n",
    "        \n",
    "        for frame_num in range(sequence_length):\n",
    "            # Generate the expected `.npy` frame path\n",
    "            frame_path = os.path.join(folder_path, f\"{os.path.splitext(video_file)[0]}_{frame_num}.npy\")\n",
    "            try:\n",
    "                # Check if the file exists and is not empty\n",
    "                if os.path.exists(frame_path) and os.path.getsize(frame_path) > 0:\n",
    "                    res = np.load(frame_path)\n",
    "                    # Verify the shape to ensure it’s as expected\n",
    "                    if res.shape[0] == 63:\n",
    "                        window.append(res)\n",
    "                    else:\n",
    "                        print(f\"Warning: Frame {frame_num} for {video_file} has unexpected shape {res.shape}.\")\n",
    "                        missing_frames = True\n",
    "                        break\n",
    "                else:\n",
    "                    print(f\"Warning: Frame {frame_num} for {video_file} in folder {folder} is missing or empty.\")\n",
    "                    missing_frames = True\n",
    "                    break  # Skip incomplete sequences if necessary\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading frame {frame_num} for {video_file}: {e}\")\n",
    "                missing_frames = True\n",
    "                break\n",
    "        \n",
    "        if not missing_frames:  # Only add complete sequences\n",
    "            sequences.append(window)\n",
    "            labels.append(label_map[folder])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to categorical\n",
    "labels = to_categorical(labels).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 30, 63)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(sequences).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 6)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(labels).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shapes - X_train: (432, 30, 63), X_test: (48, 30, 63), y_train: (432, 6), y_test: (48, 6)\n"
     ]
    }
   ],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    np.array(sequences), \n",
    "    np.array(labels), \n",
    "    test_size=0.1, \n",
    "    stratify=np.array(labels)  # Use labels for stratified splitting\n",
    ")\n",
    "\n",
    "print(f\"Data shapes - X_train: {X_train.shape}, X_test: {X_test.shape}, y_train: {y_train.shape}, y_test: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define logging directory\n",
    "log_dir = os.path.join('Logs')\n",
    "tb_callback = TensorBoard(log_dir=log_dir)\n",
    "\n",
    "# Number of subfolders/classes\n",
    "num_classes = len(subfolders)\n",
    "\n",
    "# Adjust the input shape to match the data\n",
    "input_shape = (sequence_length, 63)  # Updated for 126 features per frame (hand landmarks only)\n",
    "\n",
    "# Define the model with corrected input shape\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, return_sequences=True, activation='relu', input_shape=input_shape))\n",
    "model.add(LSTM(128, return_sequences=True, activation='relu'))\n",
    "model.add(LSTM(64, return_sequences=False, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/55\n",
      "14/14 [==============================] - 4s 45ms/step - loss: 1.6942 - categorical_accuracy: 0.2153\n",
      "Epoch 2/55\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 1.4670 - categorical_accuracy: 0.4838\n",
      "Epoch 3/55\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 2.1371 - categorical_accuracy: 0.4167\n",
      "Epoch 4/55\n",
      "14/14 [==============================] - 1s 45ms/step - loss: 1.2516 - categorical_accuracy: 0.4977\n",
      "Epoch 5/55\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 1.1205 - categorical_accuracy: 0.5833\n",
      "Epoch 6/55\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 1.0740 - categorical_accuracy: 0.6204\n",
      "Epoch 7/55\n",
      "14/14 [==============================] - 1s 63ms/step - loss: 1.0239 - categorical_accuracy: 0.5856\n",
      "Epoch 8/55\n",
      "14/14 [==============================] - 1s 59ms/step - loss: 0.7641 - categorical_accuracy: 0.7431\n",
      "Epoch 9/55\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.8086 - categorical_accuracy: 0.7014\n",
      "Epoch 10/55\n",
      "14/14 [==============================] - 1s 49ms/step - loss: 0.5473 - categorical_accuracy: 0.8727\n",
      "Epoch 11/55\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.5992 - categorical_accuracy: 0.8426\n",
      "Epoch 12/55\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 0.4359 - categorical_accuracy: 0.8449\n",
      "Epoch 13/55\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 0.6910 - categorical_accuracy: 0.7616\n",
      "Epoch 14/55\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.9349 - categorical_accuracy: 0.6412\n",
      "Epoch 15/55\n",
      "14/14 [==============================] - 1s 60ms/step - loss: 0.7375 - categorical_accuracy: 0.7546\n",
      "Epoch 16/55\n",
      "14/14 [==============================] - 1s 61ms/step - loss: 0.7477 - categorical_accuracy: 0.6574\n",
      "Epoch 17/55\n",
      "14/14 [==============================] - 1s 49ms/step - loss: 0.5239 - categorical_accuracy: 0.8843\n",
      "Epoch 18/55\n",
      "14/14 [==============================] - 1s 48ms/step - loss: 0.3680 - categorical_accuracy: 0.8843\n",
      "Epoch 19/55\n",
      "14/14 [==============================] - 1s 48ms/step - loss: 0.1891 - categorical_accuracy: 0.9699\n",
      "Epoch 20/55\n",
      "14/14 [==============================] - 1s 48ms/step - loss: 0.1284 - categorical_accuracy: 0.9745\n",
      "Epoch 21/55\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.2411 - categorical_accuracy: 0.9630\n",
      "Epoch 22/55\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.0740 - categorical_accuracy: 0.9769\n",
      "Epoch 23/55\n",
      "14/14 [==============================] - 1s 59ms/step - loss: 0.0449 - categorical_accuracy: 0.9861\n",
      "Epoch 24/55\n",
      "14/14 [==============================] - 1s 59ms/step - loss: 0.1627 - categorical_accuracy: 0.9630\n",
      "Epoch 25/55\n",
      "14/14 [==============================] - 1s 66ms/step - loss: 0.1247 - categorical_accuracy: 0.9722\n",
      "Epoch 26/55\n",
      "14/14 [==============================] - 1s 60ms/step - loss: 0.0451 - categorical_accuracy: 0.9815\n",
      "Epoch 27/55\n",
      "14/14 [==============================] - 1s 59ms/step - loss: 0.0455 - categorical_accuracy: 0.9792\n",
      "Epoch 28/55\n",
      "14/14 [==============================] - 1s 59ms/step - loss: 0.0371 - categorical_accuracy: 0.9907\n",
      "Epoch 29/55\n",
      "14/14 [==============================] - 1s 66ms/step - loss: 0.0214 - categorical_accuracy: 0.9931\n",
      "Epoch 30/55\n",
      "14/14 [==============================] - 1s 60ms/step - loss: 0.0307 - categorical_accuracy: 0.9861\n",
      "Epoch 31/55\n",
      "14/14 [==============================] - 1s 59ms/step - loss: 0.0162 - categorical_accuracy: 0.9954\n",
      "Epoch 32/55\n",
      "14/14 [==============================] - 1s 61ms/step - loss: 0.0124 - categorical_accuracy: 0.9931\n",
      "Epoch 33/55\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 0.0157 - categorical_accuracy: 0.9954\n",
      "Epoch 34/55\n",
      "14/14 [==============================] - 1s 59ms/step - loss: 0.0126 - categorical_accuracy: 0.9954\n",
      "Epoch 35/55\n",
      "14/14 [==============================] - 1s 58ms/step - loss: 0.0169 - categorical_accuracy: 0.9931\n",
      "Epoch 36/55\n",
      "14/14 [==============================] - 1s 65ms/step - loss: 0.0058 - categorical_accuracy: 0.9977\n",
      "Epoch 37/55\n",
      "14/14 [==============================] - 1s 62ms/step - loss: 0.0100 - categorical_accuracy: 0.9954\n",
      "Epoch 38/55\n",
      "14/14 [==============================] - 1s 59ms/step - loss: 0.0085 - categorical_accuracy: 0.9977\n",
      "Epoch 39/55\n",
      "14/14 [==============================] - 1s 58ms/step - loss: 0.0038 - categorical_accuracy: 1.0000\n",
      "Epoch 40/55\n",
      "14/14 [==============================] - 1s 64ms/step - loss: 0.0028 - categorical_accuracy: 0.9977\n",
      "Epoch 41/55\n",
      "14/14 [==============================] - 1s 58ms/step - loss: 0.0141 - categorical_accuracy: 0.9977\n",
      "Epoch 42/55\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 1.2790 - categorical_accuracy: 0.7986\n",
      "Epoch 43/55\n",
      "14/14 [==============================] - 1s 58ms/step - loss: 0.8020 - categorical_accuracy: 0.8056\n",
      "Epoch 44/55\n",
      "14/14 [==============================] - 1s 66ms/step - loss: 0.3305 - categorical_accuracy: 0.9398\n",
      "Epoch 45/55\n",
      "14/14 [==============================] - 1s 59ms/step - loss: 0.1842 - categorical_accuracy: 0.9421\n",
      "Epoch 46/55\n",
      "14/14 [==============================] - 1s 58ms/step - loss: 0.0623 - categorical_accuracy: 0.9838\n",
      "Epoch 47/55\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 0.1665 - categorical_accuracy: 0.9560\n",
      "Epoch 48/55\n",
      "14/14 [==============================] - 1s 65ms/step - loss: 0.2171 - categorical_accuracy: 0.9398\n",
      "Epoch 49/55\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 0.0722 - categorical_accuracy: 0.9838\n",
      "Epoch 50/55\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 0.0432 - categorical_accuracy: 0.9931\n",
      "Epoch 51/55\n",
      "14/14 [==============================] - 1s 63ms/step - loss: 0.0294 - categorical_accuracy: 0.9954\n",
      "Epoch 52/55\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 0.0187 - categorical_accuracy: 0.9954\n",
      "Epoch 53/55\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 0.0158 - categorical_accuracy: 0.9954\n",
      "Epoch 54/55\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 0.0186 - categorical_accuracy: 0.9907\n",
      "Epoch 55/55\n",
      "14/14 [==============================] - 1s 68ms/step - loss: 0.0119 - categorical_accuracy: 0.9977\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1ba67e60850>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=55, callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_12 (LSTM)              (None, 30, 64)            32768     \n",
      "                                                                 \n",
      " lstm_13 (LSTM)              (None, 30, 128)           98816     \n",
      "                                                                 \n",
      " lstm_14 (LSTM)              (None, 64)                49408     \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 6)                 198       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 187430 (732.15 KB)\n",
      "Trainable params: 187430 (732.15 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Display the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 18ms/step\n"
     ]
    }
   ],
   "source": [
    "res = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 9ms/step - loss: 0.0246 - categorical_accuracy: 0.9792\n",
      "Test Loss: 0.024570098146796227, Test Accuracy: 0.9791666865348816\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 10ms/step\n",
      "Class hello (label 0): Correctly Recognized 7/8 videos (87.50% accuracy)\n",
      "Class goodbye (label 1): Correctly Recognized 8/8 videos (100.00% accuracy)\n",
      "Class please (label 2): Correctly Recognized 8/8 videos (100.00% accuracy)\n",
      "Class thankyou (label 3): Correctly Recognized 8/8 videos (100.00% accuracy)\n",
      "Class yes (label 4): Correctly Recognized 8/8 videos (100.00% accuracy)\n",
      "Class no (label 5): Correctly Recognized 8/8 videos (100.00% accuracy)\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "yhat = model.predict(X_test)\n",
    "ytrue = np.argmax(y_test, axis=1)  # Convert one-hot encoded labels to class indices\n",
    "yhat = np.argmax(yhat, axis=1)  # Get predicted class indices\n",
    "\n",
    "# Initialize a dictionary to count correct predictions for each subfolder\n",
    "correct_predictions_per_class = {label: 0 for label in label_map.values()}\n",
    "total_videos_per_class = {label: 0 for label in label_map.values()}\n",
    "\n",
    "# Count total and correct predictions for each class\n",
    "for true_label, predicted_label in zip(ytrue, yhat):\n",
    "    total_videos_per_class[true_label] += 1\n",
    "    if true_label == predicted_label:\n",
    "        correct_predictions_per_class[true_label] += 1\n",
    "\n",
    "# Print the results\n",
    "for folder, label in label_map.items():\n",
    "    total = total_videos_per_class[label]\n",
    "    correct = correct_predictions_per_class[label]\n",
    "    print(f\"Class {folder} (label {label}): Correctly Recognized {correct}/{total} videos ({(correct / total) * 100:.2f}% accuracy)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('action.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0246 - categorical_accuracy: 0.9792\n",
      "Test Loss: 0.024570098146796227, Test Accuracy: 0.9791666865348816\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 17ms/step\n",
      "Confusion Matrix:\n",
      " [[[40  0]\n",
      "  [ 1  7]]\n",
      "\n",
      " [[40  0]\n",
      "  [ 0  8]]\n",
      "\n",
      " [[40  0]\n",
      "  [ 0  8]]\n",
      "\n",
      " [[40  0]\n",
      "  [ 0  8]]\n",
      "\n",
      " [[39  1]\n",
      "  [ 0  8]]\n",
      "\n",
      " [[40  0]\n",
      "  [ 0  8]]]\n",
      "Accuracy Score: 0.9791666666666666\n"
     ]
    }
   ],
   "source": [
    "# Calculate multilabel confusion matrix and accuracy\n",
    "yhat = model.predict(X_test)\n",
    "ytrue = np.argmax(y_test, axis=1).tolist()\n",
    "yhat = np.argmax(yhat, axis=1).tolist()\n",
    "print(\"Confusion Matrix:\\n\", multilabel_confusion_matrix(ytrue, yhat))\n",
    "print(\"Accuracy Score:\", accuracy_score(ytrue, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
